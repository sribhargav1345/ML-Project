{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":101598,"sourceType":"datasetVersion","datasetId":53376},{"sourceId":1400106,"sourceType":"datasetVersion","datasetId":818027}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imutils\nimport numpy as np\nimport pandas as pd\nimport os\nimport random\nimport cv2\nimport imutils\nimport random\nfrom sklearn import svm\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction import image\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-11-23T16:32:19.087793Z","iopub.execute_input":"2023-11-23T16:32:19.088596Z","iopub.status.idle":"2023-11-23T16:32:30.746549Z","shell.execute_reply.started":"2023-11-23T16:32:19.088561Z","shell.execute_reply":"2023-11-23T16:32:30.745363Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: imutils in /opt/conda/lib/python3.10/site-packages (0.5.4)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Pre-Processing","metadata":{}},{"cell_type":"code","source":"dir = \"../input/handwritten-characters/Train/\"\ntrain_data = []\nimg_size = 32\nnon_chars = [\"#\", \"$\", \"&\", \"@\"]\nfor i in os.listdir(dir):\n    if i in non_chars:\n        continue\n    count = 0\n    sub_directory = os.path.join(dir, i)\n    for j in os.listdir(sub_directory):\n        count += 1\n        if count > 4000:\n            break\n        img = cv2.imread(os.path.join(sub_directory, j), 0)\n        img = cv2.resize(img, (img_size, img_size))\n        train_data.append([img, i])","metadata":{"execution":{"iopub.status.busy":"2023-11-23T16:32:30.748611Z","iopub.execute_input":"2023-11-23T16:32:30.748938Z","iopub.status.idle":"2023-11-23T16:34:27.315125Z","shell.execute_reply.started":"2023-11-23T16:32:30.748906Z","shell.execute_reply":"2023-11-23T16:34:27.314157Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"val_dir = \"../input/handwritten-characters/Validation/\"\nval_data = []\nimg_size = 32\nfor i in os.listdir(val_dir):\n    if i in non_chars:\n        continue\n    count = 0\n    sub_directory = os.path.join(val_dir, i)\n    for j in os.listdir(sub_directory):\n        count += 1\n        if count > 1000:\n            break\n        img = cv2.imread(os.path.join(sub_directory, j), 0)\n        img = cv2.resize(img, (img_size, img_size))\n        val_data.append([img, i])","metadata":{"execution":{"iopub.status.busy":"2023-11-23T16:52:08.466437Z","iopub.execute_input":"2023-11-23T16:52:08.467200Z","iopub.status.idle":"2023-11-23T16:52:34.473243Z","shell.execute_reply.started":"2023-11-23T16:52:08.467165Z","shell.execute_reply":"2023-11-23T16:52:34.472278Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"random.shuffle(train_data)\nrandom.shuffle(val_data)\n\ntrain_X = []\ntrain_Y = []\nfor features, label in train_data:\n    train_X.append(features)\n    train_Y.append(label)\n\nval_X = []\nval_Y = []\nfor features, label in val_data:\n    val_X.append(features)\n    val_Y.append(label)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T16:52:34.475144Z","iopub.execute_input":"2023-11-23T16:52:34.475817Z","iopub.status.idle":"2023-11-23T16:52:34.711464Z","shell.execute_reply.started":"2023-11-23T16:52:34.475782Z","shell.execute_reply":"2023-11-23T16:52:34.710431Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extraction","metadata":{}},{"cell_type":"code","source":"# Extract features from images\nn_samples = len(train_X)\nn_features = img_size * img_size\ntrain_X = np.array(train_X).reshape(n_samples, -1)\n\nn_samples_val = len(val_X)\nval_X = np.array(val_X).reshape(n_samples_val, -1)\n\n# Scale the data\nn_components = 64  # Adjust the number of components as needed\npca = PCA(n_components=n_components, svd_solver='randomized', whiten=True).fit(train_X)\n\ntrain_X = pca.transform(train_X)\nval_X = pca.transform(val_X)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T16:52:34.712507Z","iopub.execute_input":"2023-11-23T16:52:34.712791Z","iopub.status.idle":"2023-11-23T16:52:47.772217Z","shell.execute_reply.started":"2023-11-23T16:52:34.712766Z","shell.execute_reply":"2023-11-23T16:52:47.770753Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Training SVM model","metadata":{}},{"cell_type":"code","source":"# SVM model\nsvm_model = svm.SVC(kernel='linear', C=1.0)\n\n# Train the SVM\nsvm_model.fit(train_X, train_Y)\n\n# Make predictions on the validation set\nval_Y_pred = svm_model.predict(val_X)\n\n# Evaluate the SVM model\naccuracy = accuracy_score(val_Y, val_Y_pred)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-11-23T16:52:47.775460Z","iopub.execute_input":"2023-11-23T16:52:47.776233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nfilename = 'finalized_model.sav'\npickle.dump(svm_model, open(filename, 'wb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model = pickle.load(open(filename, 'rb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing on characters","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\n# Load and preprocess the test image\ntest_image_path = '/kaggle/input/handwritten-characters/Validation/4/0.jpg'\nimg = cv2.imread(test_image_path, 0)  # Load the image in grayscale\nplt.imshow(img)\nimg = cv2.resize(img, (img_size, img_size))  # Resize to the same dimensions as training data\n\n# Flatten the image into a 1D array\nimg_flat = img.reshape(-1)\n\n# If necessary, apply the same preprocessing as you did for training data, such as PCA transformation or normalization.\nimg_transformed = pca.transform([img_flat])  # If you applied PCA transformation\n\n# Make predictions using the SVM model\npredn = svm_model.predict(img_transformed)\nprint(predn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\n# Load and preprocess the test image\ntest_image_path = '/kaggle/input/handwritten-characters/Validation/2/0.jpg'\nimg = cv2.imread(test_image_path, 0)  # Load the image in grayscale\n\nimg = cv2.resize(img, (img_size, img_size))  # Resize to the same dimensions as training data\nplt.imshow(img)\n# Flatten the image into a 1D array\nimg_flat = img.reshape(-1)\n\n# If necessary, apply the same preprocessing as you did for training data, such as PCA transformation or normalization.\nimg_transformed = pca.transform([img_flat])  # If you applied PCA transformation\n\n# Make predictions using the SVM model\npredn = svm_model.predict(img_transformed)\nprint(predn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sort_contours(cnts, method=\"left-to-right\"):\n    reverse = False\n    i = 0\n    if method == \"right-to-left\" or method == \"bottom-to-top\":\n        reverse = True\n    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n        i = 1\n    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n    key=lambda b:b[1][i], reverse=reverse))\n    # return the list of sorted contours and bounding boxes\n    return (cnts, boundingBoxes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grapheme segmentation","metadata":{}},{"cell_type":"code","source":"import cv2\nimport imutils\nimport numpy as np\n\ndef grapheme_segmentation(img):\n    graphemes = []\n    image = cv2.imread(img)\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    ret, thresh1 = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n    dilated = cv2.dilate(thresh1, None, iterations=2)\n\n    cnts = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = imutils.grab_contours(cnts)\n    cnts = sort_contours(cnts, method=\"left-to-right\")[0]\n    \n    for c in cnts:\n        if cv2.contourArea(c) > 10:\n            (x, y, w, h) = cv2.boundingRect(c)\n            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n            roi = gray[y:y + h, x:x + w]\n            graphemes.append(roi)\n    \n    return graphemes, image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recognize_characters(graphemes, svm_model, pca, img_size):\n    letters = []\n    \n    for roi in graphemes:\n        thresh = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n        thresh = cv2.resize(thresh, (img_size, img_size), interpolation=cv2.INTER_CUBIC)\n        img_flat = thresh.reshape(-1)\n        thresh = pca.transform([img_flat])\n        ypred = svm_model.predict(thresh)\n        letters.append(ypred[0])\n    \n    return letters","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_word(letter):\n    word = \"\".join(letter)\n    return word","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = 32\n\nimg_path = '/kaggle/input/handwriting-recognition/test_v2/test/TEST_0005.jpg'\n\ngraphemes, image = grapheme_segmentation(img_path)\nletters = recognize_characters(graphemes, svm_model, pca, img_size)\nword = get_word(letters)\nprint(\"Recognized Word:\", word)\nplt.imshow(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K-Means Clustering","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors\n\nn_clusters = 40\n\nkmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(train_X)\nnn_model = NearestNeighbors(n_neighbors=10, algorithm='ball_tree').fit(kmeans.cluster_centers_)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-23T16:32:11.286387Z","iopub.status.idle":"2023-11-23T16:32:11.286716Z","shell.execute_reply.started":"2023-11-23T16:32:11.286555Z","shell.execute_reply":"2023-11-23T16:32:11.286571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct_predictions = 0\ntotal_samples = len(val_X)\n\nfor i in range(total_samples):\n    nearest_cluster_index = nn_model.kneighbors(val_X, n_neighbors=1)[1][0][0]\n    \n    predicted_character = train_Y[np.where(kmeans.labels_ == nearest_cluster_index)[0][0]]\n    \n    if predicted_character == val_Y[i]:\n        correct_predictions += 1\naccuracy = (correct_predictions / total_samples) * 30\nprint(f\"Accuracy using Nearest Neighbors with K-means: {accuracy*100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-11-23T16:32:11.287614Z","iopub.status.idle":"2023-11-23T16:32:11.287949Z","shell.execute_reply.started":"2023-11-23T16:32:11.287781Z","shell.execute_reply":"2023-11-23T16:32:11.287797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Phase-2","metadata":{}},{"cell_type":"markdown","source":"**Step1** : Build a digit(0-9) + A-Z characters classifier using a CNN architecture. \n\n**Step2**: Apply character segmentation for the handwritten word image.\n\n**Step3**: Classify each segmented letter and then get the final word in the image.","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nimport seaborn as sns\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom keras import backend as K\nfrom keras.layers import Dense, Activation, Flatten, Dense,MaxPooling2D, Dropout\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LB = LabelBinarizer()\ntrain_Y = LB.fit_transform(train_Y)\nval_Y = LB.fit_transform(val_Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_X.shape,val_X.shape)\nprint(train_X.shape,val_X.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding = \"same\", activation='relu', input_shape=(32,32,1)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n \nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(35, activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_X,train_Y, epochs=5, batch_size=32, validation_data = (val_X, val_Y),  verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}