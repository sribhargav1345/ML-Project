{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7063865,
          "sourceType": "datasetVersion",
          "datasetId": 4067035
        },
        {
          "sourceId": 7064030,
          "sourceType": "datasetVersion",
          "datasetId": 4067161
        },
        {
          "sourceId": 7064083,
          "sourceType": "datasetVersion",
          "datasetId": 4067203
        },
        {
          "sourceId": 7064120,
          "sourceType": "datasetVersion",
          "datasetId": 4067226
        },
        {
          "sourceId": 7083122,
          "sourceType": "datasetVersion",
          "datasetId": 4080679
        },
        {
          "sourceId": 7083155,
          "sourceType": "datasetVersion",
          "datasetId": 4080706
        },
        {
          "sourceId": 7083166,
          "sourceType": "datasetVersion",
          "datasetId": 4080714
        },
        {
          "sourceId": 7083588,
          "sourceType": "datasetVersion",
          "datasetId": 4081018
        }
      ],
      "dockerImageVersionId": 30587,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow\n",
        "!pip install numpy"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-29T18:51:40.148392Z",
          "iopub.execute_input": "2023-11-29T18:51:40.148834Z",
          "iopub.status.idle": "2023-11-29T18:52:02.784690Z",
          "shell.execute_reply.started": "2023-11-29T18:51:40.148799Z",
          "shell.execute_reply": "2023-11-29T18:52:02.783637Z"
        },
        "trusted": true,
        "id": "WShIaV-P1ohI",
        "outputId": "b13d3b38-347e-48a6-8375-d5c012874c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (10.1.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.24.3)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "These commands use the pip package manager to install two Python packages. The first command installs the \"Pillow\" library, which is a powerful image processing library. The second command installs \"NumPy,\" a fundamental package for scientific computing with Python, providing support for large, multi-dimensional arrays and matrices."
      ],
      "metadata": {
        "id": "jxqYZfQc1ohK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While seeking ways to enhance the accuracy of our existing models, I came across an article highlighting the challenge of recognizing sequential printed texts that have become blurred and noisy over time due to repeated use. Intrigued by this issue, I explored models capable of addressing such challenges and discovered Hidden Markov Models (HMMs), which leverage probabilities for recognition. Upon implementing HMMs, I observed notable improvements in text recognition for degraded and distorted printed texts."
      ],
      "metadata": {
        "id": "aD0JjUXv1ohL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import sys\n",
        "import math\n",
        "import numpy as np\n",
        "CHARACTER_WIDTH=14\n",
        "CHARACTER_HEIGHT=25\n",
        "TRAIN_LETTERS=\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789(),.-!?\\\"' \"\n",
        "\n",
        "def load_letters(fname):\n",
        "    im = Image.open(fname)\n",
        "    px = im.load()\n",
        "    (x_size, y_size) = im.size\n",
        "    print(im.size)\n",
        "    print(int(x_size / CHARACTER_WIDTH) * CHARACTER_WIDTH)\n",
        "    result = []\n",
        "    for x_beg in range(0, int(x_size / CHARACTER_WIDTH) * CHARACTER_WIDTH, CHARACTER_WIDTH):\n",
        "        result += [ [ \"\".join([ '*' if px[x, y] < 1 else ' ' for x in range(x_beg, x_beg+CHARACTER_WIDTH) ]) for y in range(0, CHARACTER_HEIGHT) ], ]\n",
        "    return result\n",
        "\n",
        "def load_training_letters(fname):\n",
        "    TRAIN_LETTERS=\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789(),.-!?\\\"' \"\n",
        "    letter_images = load_letters(fname)\n",
        "    return { TRAIN_LETTERS[i]: letter_images[i] for i in range(0, len(TRAIN_LETTERS) ) }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-29T18:52:10.989320Z",
          "iopub.execute_input": "2023-11-29T18:52:10.989716Z",
          "iopub.status.idle": "2023-11-29T18:52:11.001237Z",
          "shell.execute_reply.started": "2023-11-29T18:52:10.989686Z",
          "shell.execute_reply": "2023-11-29T18:52:10.999711Z"
        },
        "trusted": true,
        "id": "riq49k-81ohM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines functions for loading training letters from an image file. It utilizes the Pillow (PIL) library for image processing. The load_letters function takes an image file, converts it into a pixel matrix, and extracts character-sized blocks, storing them as binary strings in a list. The load_training_letters function maps these binary strings to corresponding characters in the TRAIN_LETTERS string, creating a dictionary where each character is associated with its respective pixel representation."
      ],
      "metadata": {
        "id": "qcMx_7QL1ohN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_trans(filename):\n",
        "    train_txt = open(\"/kaggle/input/ntguyf-7/12345.txt\",'r')\n",
        "    lines = train_txt.readlines()\n",
        "\n",
        "    file_temp = []\n",
        "    word_temp=[]\n",
        "    for line in lines:\n",
        "        for word in line.split():\n",
        "            word_temp.append(word)\n",
        "        for a in line:\n",
        "            file_temp.append(a)\n",
        "    init_temp = [0]*len(TRAIN_LETTERS)\n",
        "\n",
        "    for a in range(len(TRAIN_LETTERS)):\n",
        "        for w in word_temp:\n",
        "            if TRAIN_LETTERS[a] == w[0]:\n",
        "                init_temp[a] +=1\n",
        "\n",
        "        for a in line:\n",
        "            file_temp.append(a)\n",
        "    train_txt.close()\n",
        "    init = [(i+1)/(len(word_temp)+2) for i in init_temp]\n",
        "    trans = np.zeros(shape=(len(TRAIN_LETTERS), len(TRAIN_LETTERS)))\n",
        "    for i in range(0,len(file_temp)):\n",
        "        if file_temp[i] in TRAIN_LETTERS and file_temp[i+1] in TRAIN_LETTERS:\n",
        "            t_index = TRAIN_LETTERS.index(file_temp[i])\n",
        "            t1_index = TRAIN_LETTERS.index(file_temp[i+1])\n",
        "            trans[t_index,t1_index] += 1\n",
        "    rows_sum = np.sum(trans,axis=1)\n",
        "    for i in range(0,len(TRAIN_LETTERS)):\n",
        "        for j in range(0,len(TRAIN_LETTERS)):\n",
        "            trans[i,j] = (trans[i,j] + 1)/(rows_sum[i]+2) #Laplace Smoothing\n",
        "\n",
        "    return init,trans\n",
        "\n",
        "def calc_emission_prob():\n",
        "    noise = 0.42\n",
        "    num_i = len(train_letters)\n",
        "    num_j = len(test_letters)\n",
        "    emissions = np.zeros(shape=(num_i,num_j))\n",
        "    for letter in train_letters:\n",
        "        for j in range(num_j):\n",
        "            val = train_letters.get(letter)\n",
        "            obs = test_letters[j]\n",
        "            mis = 0\n",
        "            match = 0\n",
        "            for m in range(25):\n",
        "                for n in range(14):\n",
        "                    if val[m][n] != obs[m][n]:\n",
        "                        mis += 1 #the number of mismatched pixels\n",
        "                    else:\n",
        "                        match += 1 #the number of matched pixels\n",
        "            emissions[TRAIN_LETTERS.index(letter)][j] = (math.pow(1-noise,match)) * (math.pow(noise,mis))\n",
        "\n",
        "    return emissions"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-29T18:52:16.090279Z",
          "iopub.execute_input": "2023-11-29T18:52:16.090704Z",
          "iopub.status.idle": "2023-11-29T18:52:16.104913Z",
          "shell.execute_reply.started": "2023-11-29T18:52:16.090669Z",
          "shell.execute_reply": "2023-11-29T18:52:16.103554Z"
        },
        "trusted": true,
        "id": "1rY09pNq1ohN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines two functions for initializing transition probabilities and calculating emission probabilities for a Hidden Markov Model (HMM). The init_trans function computes the initial state probabilities (init) and transition probabilities (trans) between letters in the TRAIN_LETTERS set. It uses Laplace Smoothing to handle cases where certain transitions have zero occurrences. The calc_emission_prob function calculates emission probabilities based on pixel comparisons between training and test letters, incorporating a noise factor. It computes the likelihood of observing a test letter given a training letter and returns a matrix of emission probabilities (emissions). The code is likely part of a broader HMM-based pattern recognition or classification system."
      ],
      "metadata": {
        "id": "Mt7gfl6N1ohO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simplified(test_letters,init,ems):\n",
        "    init =init\n",
        "    emission = ems\n",
        "    obs = test_letters\n",
        "    rows = len(TRAIN_LETTERS)\n",
        "    cols = len(obs)\n",
        "    y = np.zeros(cols)\n",
        "    temp_results = np.zeros(shape=(rows,cols))\n",
        "    for i in range(0,cols):\n",
        "        for j in range(0,rows):\n",
        "            temp_results[j,i] = emission[j,i]\n",
        "    y = np.argmax(temp_results, axis=0)\n",
        "    return y\n",
        "def hmm_ve(test_letters,init,ems,trans):\n",
        "    init =init\n",
        "    emission = ems\n",
        "    transition = trans\n",
        "    obs = test_letters\n",
        "    rows = len(TRAIN_LETTERS)\n",
        "    cols = len(obs)\n",
        "    out = np.zeros(shape=(rows,cols))\n",
        "    for i in range(rows):\n",
        "        out[i,0] = init[i] * emission[i,0]\n",
        "    for i in range(cols):\n",
        "        for j in range(rows):\n",
        "            temp =0\n",
        "            for k in range(rows):\n",
        "                temp += init[k]*transition[k,i]\n",
        "            out[j,i] = temp* emission[j,i]\n",
        "    indexes = np.argmax(out,axis=0)\n",
        "    return indexes\n",
        "def viterbi(test_letters,init,trans,ems):\n",
        "    obs = test_letters\n",
        "    init = init\n",
        "    transition = trans\n",
        "    emission = ems\n",
        "    t = len(obs)\n",
        "    rows = len(train_letters)\n",
        "    v_it = np.zeros(shape=(rows,t))\n",
        "    max_path =  np.empty(shape=(rows,t),dtype=int)\n",
        "    for i in range(rows):\n",
        "        v_it[i,0] = math.log(init[i]) + math.log(emission[i,0])\n",
        "    for j in range(1,t):\n",
        "        for i in range(rows):\n",
        "            temp_val = []\n",
        "            for k in range(rows):\n",
        "                temp_val.append(v_it[k,j-1] + math.log(transition[k,i] ) +math.log(emission[i,j]))\n",
        "            max_state = max(temp_val)\n",
        "            v_it[i,j] = max_state\n",
        "            max_path[i,j] = temp_val.index(max_state)\n",
        "    most_likely = np.zeros(t,dtype=int)\n",
        "    most_likely[-1] = np.argmax(v_it[:,-1])\n",
        "    for i in range(1,t)[::-1]:\n",
        "        most_likely[i-1] = max_path[most_likely[i],i]\n",
        "    return most_likely"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-29T18:50:18.810401Z",
          "iopub.execute_input": "2023-11-29T18:50:18.810775Z",
          "iopub.status.idle": "2023-11-29T18:50:18.825559Z",
          "shell.execute_reply.started": "2023-11-29T18:50:18.810747Z",
          "shell.execute_reply": "2023-11-29T18:50:18.824127Z"
        },
        "trusted": true,
        "id": "2avbwmj91ohO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "simplified: This function performs the simplified HMM algorithm, where for each observation in test_letters, it selects the state with the highest emission probability from the matrix ems. The resulting sequence of state indices is returned.\n",
        "\n",
        "hmm_ve: This function implements the HMM algorithm using the Viterbi algorithm. It computes the most likely state sequence for the given observations in test_letters based on the initial probabilities (init), transition probabilities (trans), and emission probabilities (ems).\n",
        "\n",
        "viterbi: This function is a more detailed implementation of the Viterbi algorithm. It calculates the log probabilities of all possible state sequences and efficiently finds the most likely sequence given the observations in test_letters, initial probabilities (init), transition probabilities (trans), and emission probabilities (ems)."
      ],
      "metadata": {
        "id": "2PDwz1Bd1ohP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_fname = \"/kaggle/input/ntguyf-7/courier-train.png\"\n",
        "train_txt_fname = \"/kaggle/input/ntguyf-7/12345.txt\"\n",
        "test_img_fname = \"/kaggle/input/iuasdfh/test-5-0.png\"\n",
        "train_letters = load_training_letters(train_img_fname)\n",
        "test_letters = load_letters(test_img_fname)\n",
        "init, trans = init_trans(train_txt_fname)\n",
        "ems = calc_emission_prob()\n",
        "simple = simplified(test_letters,init,ems)\n",
        "print (\"Simple: \"+\"\".join([TRAIN_LETTERS[i] for i in simple]))\n",
        "hmm_out = hmm_ve(test_letters,init,ems,trans)\n",
        "print (\"HMM VE: \" + \"\".join([TRAIN_LETTERS[i] for i in hmm_out]))\n",
        "output = viterbi(test_letters,init,trans,ems)\n",
        "print (\"HMM MAP: \" + \"\".join([TRAIN_LETTERS[i] for i in output]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-29T18:52:20.938620Z",
          "iopub.execute_input": "2023-11-29T18:52:20.939004Z",
          "iopub.status.idle": "2023-11-29T18:52:21.898471Z",
          "shell.execute_reply.started": "2023-11-29T18:52:20.938973Z",
          "shell.execute_reply": "2023-11-29T18:52:21.897329Z"
        },
        "trusted": true,
        "id": "XMa9hE401ohQ",
        "outputId": "4d70c2d6-9f1a-4a55-ace7-b9ecc2ff6d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(1008, 25)\n1008\n(281, 25)\n280\nSimple: Opinion of the Ccurt\nHMM VE: Opinion of the Ccurt\nHMM MAP: Opinion of the Court\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_fname = \"/kaggle/input/ntguyf-7/courier-train.png\"\n",
        "train_txt_fname = \"/kaggle/input/ntguyf-7/12345.txt\"\n",
        "test_img_fname = \"/kaggle/input/new-data/test-15-0.png\"\n",
        "train_letters = load_training_letters(train_img_fname)\n",
        "test_letters = load_letters(test_img_fname)\n",
        "init, trans = init_trans(train_txt_fname)\n",
        "ems = calc_emission_prob()\n",
        "simple = simplified(test_letters,init,ems)\n",
        "print (\"Simple: \"+\"\".join([TRAIN_LETTERS[i] for i in simple]))\n",
        "hmm_out = hmm_ve(test_letters,init,ems,trans)\n",
        "print (\"HMM VE: \" + \"\".join([TRAIN_LETTERS[i] for i in hmm_out]))\n",
        "output = viterbi(test_letters,init,trans,ems)\n",
        "print (\"HMM MAP: \" + \"\".join([TRAIN_LETTERS[i] for i in output]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-29T18:52:33.121779Z",
          "iopub.execute_input": "2023-11-29T18:52:33.122190Z",
          "iopub.status.idle": "2023-11-29T18:52:34.317495Z",
          "shell.execute_reply.started": "2023-11-29T18:52:33.122156Z",
          "shell.execute_reply": "2023-11-29T18:52:34.316518Z"
        },
        "trusted": true,
        "id": "p3cH_P791ohR",
        "outputId": "59e7aa85-3d67-4091-93f2-d8adf0c5d3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(1008, 25)\n1008\n(561, 25)\n560\nSimple: The Constitut1on grants them that r1ght.\nHMM VE: The Constitut1on grants them that r1ght.\nHMM MAP: The Constitution grants them that right.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_fname = \"/kaggle/input/ntguyf-7/courier-train.png\"\n",
        "train_txt_fname = \"/kaggle/input/ntguyf-7/12345.txt\"\n",
        "test_img_fname = \"/kaggle/input/new-data/test-17-0.png\"\n",
        "train_letters = load_training_letters(train_img_fname)\n",
        "test_letters = load_letters(test_img_fname)\n",
        "init, trans = init_trans(train_txt_fname)\n",
        "ems = calc_emission_prob()\n",
        "simple = simplified(test_letters,init,ems)\n",
        "print (\"Simple: \"+\"\".join([TRAIN_LETTERS[i] for i in simple]))\n",
        "hmm_out = hmm_ve(test_letters,init,ems,trans)\n",
        "print (\"HMM VE: \" + \"\".join([TRAIN_LETTERS[i] for i in hmm_out]))\n",
        "output = viterbi(test_letters,init,trans,ems)\n",
        "print (\"HMM MAP: \" + \"\".join([TRAIN_LETTERS[i] for i in output]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-29T18:52:36.587504Z",
          "iopub.execute_input": "2023-11-29T18:52:36.587935Z",
          "iopub.status.idle": "2023-11-29T18:52:37.498102Z",
          "shell.execute_reply.started": "2023-11-29T18:52:36.587899Z",
          "shell.execute_reply": "2023-11-29T18:52:37.497312Z"
        },
        "trusted": true,
        "id": "pRr_hLfB1ohS",
        "outputId": "5a2508fd-39b9-4239-ac54-dc8328fbf459"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(1008, 25)\n1008\n(239, 25)\n238\nSimple: 1t 1s so orcerec.\nHMM VE: 1t 1s so orcerec.\nHMM MAP: It is so ordered.\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}